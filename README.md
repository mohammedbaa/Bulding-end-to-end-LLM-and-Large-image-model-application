About

This project demonstrates an end-to-end Large Language Model (LLM) and Large Vision Model (LVM) application built using Google Gemini and Streamlit.

The application showcases how modern multimodal AI systems can be integrated into real-world user interfaces, supporting:

Text-based question answering

Conversational chat with memory

Image understanding and visual reasoning

The project follows best practices for:

Secure API key management using environment variables

Modular code organization

Scalable deployment readiness

It is designed for educational purposes, AI engineering portfolios, and rapid prototyping, providing a practical reference for building and deploying multimodal AI application
